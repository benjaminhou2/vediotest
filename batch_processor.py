# æ‰¹é‡å¤„ç†å™¨æ¨¡å—
import os
import sys
import json
import csv
import time
import argparse
from datetime import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from itertools import combinations
import traceback

from video_analyzer import VideoAnalyzer
from config import config
from utils import (
    validate_video_file, get_file_info, format_duration,
    ProgressTracker, calculate_overall_similarity, is_similar,
    clean_temp_files, ensure_directory
)

class BatchProcessor:
    """æ‰¹é‡è§†é¢‘å¤„ç†å™¨"""
    
    def __init__(self):
        self.config = config
        self.analyzer = None
        self.results = []
        
    def initialize_analyzer(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        if self.analyzer is None:
            print("ğŸ”„ åˆå§‹åŒ–è§†é¢‘åˆ†æå™¨...")
            self.analyzer = VideoAnalyzer()
            print("âœ… åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def find_video_files(self, directory: str, recursive: bool = True) -> list:
        """
        åœ¨ç›®å½•ä¸­æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
        
        Args:
            directory: æœç´¢ç›®å½•
            recursive: æ˜¯å¦é€’å½’æœç´¢å­ç›®å½•
        
        Returns:
            è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        video_files = []
        search_path = Path(directory)
        
        if not search_path.exists():
            raise ValueError(f"ç›®å½•ä¸å­˜åœ¨: {directory}")
        
        # æ”¯æŒçš„è§†é¢‘æ ¼å¼
        video_extensions = set(self.config.files.supported_formats)
        
        if recursive:
            pattern = "**/*"
        else:
            pattern = "*"
        
        for file_path in search_path.glob(pattern):
            if file_path.is_file() and file_path.suffix.lower() in video_extensions:
                # éªŒè¯æ–‡ä»¶
                valid, _ = validate_video_file(str(file_path), self.config.files.max_file_size_mb)
                if valid:
                    video_files.append(str(file_path))
                else:
                    print(f"âš ï¸  è·³è¿‡æ— æ•ˆæ–‡ä»¶: {file_path.name}")
        
        return sorted(video_files)
    
    def compare_file_pair(self, video_pair: tuple) -> dict:
        """
        æ¯”è¾ƒä¸€å¯¹è§†é¢‘æ–‡ä»¶
        
        Args:
            video_pair: (video1_path, video2_path)
        
        Returns:
            æ¯”è¾ƒç»“æœå­—å…¸
        """
        video1_path, video2_path = video_pair
        
        try:
            result = self.analyzer.analyze_video_similarity(video1_path, video2_path)
            
            # æ·»åŠ é¢å¤–ä¿¡æ¯
            result.update({
                'video1_file': os.path.basename(video1_path),
                'video2_file': os.path.basename(video2_path),
                'video1_full_path': video1_path,
                'video2_full_path': video2_path,
                'comparison_id': f"{os.path.basename(video1_path)}_vs_{os.path.basename(video2_path)}"
            })
            
            return result
            
        except Exception as e:
            error_result = {
                'video1_file': os.path.basename(video1_path),
                'video2_file': os.path.basename(video2_path),
                'video1_full_path': video1_path,
                'video2_full_path': video2_path,
                'comparison_id': f"{os.path.basename(video1_path)}_vs_{os.path.basename(video2_path)}",
                'error': str(e),
                'traceback': traceback.format_exc(),
                'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            print(f"âŒ æ¯”è¾ƒå¤±è´¥ {os.path.basename(video1_path)} vs {os.path.basename(video2_path)}: {e}")
            return error_result
    
    def batch_compare_directory(self, directory: str, recursive: bool = True, 
                              max_workers: int = None, output_file: str = None) -> list:
        """
        æ‰¹é‡æ¯”è¾ƒç›®å½•ä¸­çš„æ‰€æœ‰è§†é¢‘
        
        Args:
            directory: è§†é¢‘ç›®å½•
            recursive: æ˜¯å¦é€’å½’æœç´¢
            max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œæ•°
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        Returns:
            æ¯”è¾ƒç»“æœåˆ—è¡¨
        """
        print(f"ğŸ” æœç´¢ç›®å½•: {directory}")
        
        # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
        video_files = self.find_video_files(directory, recursive)
        
        if len(video_files) < 2:
            print(f"âš ï¸  ç›®å½•ä¸­æ‰¾åˆ°çš„è§†é¢‘æ–‡ä»¶ä¸è¶³2ä¸ª ({len(video_files)}ä¸ª)")
            return []
        
        print(f"ğŸ“ æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
        
        # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„é…å¯¹
        video_pairs = list(combinations(video_files, 2))
        total_comparisons = len(video_pairs)
        
        print(f"ğŸ”„ éœ€è¦è¿›è¡Œ {total_comparisons} æ¬¡æ¯”è¾ƒ")
        
        if total_comparisons > 100:
            response = input(f"âš ï¸  å°†è¿›è¡Œ {total_comparisons} æ¬¡æ¯”è¾ƒï¼Œå¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´ã€‚æ˜¯å¦ç»§ç»­ï¼Ÿ (y/n): ")
            if response.lower() != 'y':
                print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                return []
        
        # åˆå§‹åŒ–åˆ†æå™¨
        self.initialize_analyzer()
        
        # è®¾ç½®å¹¶è¡Œå·¥ä½œæ•°
        if max_workers is None:
            max_workers = min(self.config.processing.max_workers, total_comparisons)
        
        print(f"âš™ï¸  ä½¿ç”¨ {max_workers} ä¸ªå¹¶è¡Œå·¥ä½œè¿›ç¨‹")
        
        # æ‰§è¡Œæ‰¹é‡æ¯”è¾ƒ
        results = []
        start_time = time.time()
        progress = ProgressTracker(total_comparisons, "æ‰¹é‡æ¯”è¾ƒè¿›åº¦")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            futures = {executor.submit(self.compare_file_pair, pair): pair 
                      for pair in video_pairs}
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(futures):
                try:
                    result = future.result()
                    results.append(result)
                    
                    # æ›´æ–°è¿›åº¦
                    pair = futures[future]
                    message = f"å®Œæˆ: {os.path.basename(pair[0])} vs {os.path.basename(pair[1])}"
                    progress.update(1, message)
                    
                except Exception as e:
                    print(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
                    progress.update(1, "å¤±è´¥")
        
        progress.finish("æ‰¹é‡æ¯”è¾ƒå®Œæˆ")
        
        total_time = time.time() - start_time
        print(f"â±ï¸  æ€»ç”¨æ—¶: {format_duration(total_time)}")
        print(f"ğŸ“Š å¹³å‡æ¯æ¬¡æ¯”è¾ƒ: {format_duration(total_time / total_comparisons)}")
        
        # ä¿å­˜ç»“æœ
        if output_file:
            self.save_results(results, output_file)
        else:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            default_output = os.path.join(self.config.files.output_dir, 
                                        f"batch_comparison_{timestamp}.json")
            self.save_results(results, default_output)
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self.generate_summary_report(results, directory)
        
        return results
    
    def batch_compare_file_list(self, file_list: list, output_file: str = None) -> list:
        """
        æ‰¹é‡æ¯”è¾ƒæŒ‡å®šçš„æ–‡ä»¶åˆ—è¡¨
        
        Args:
            file_list: è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        Returns:
            æ¯”è¾ƒç»“æœåˆ—è¡¨
        """
        # éªŒè¯æ–‡ä»¶
        valid_files = []
        for file_path in file_list:
            valid, error = validate_video_file(file_path, self.config.files.max_file_size_mb)
            if valid:
                valid_files.append(file_path)
            else:
                print(f"âš ï¸  è·³è¿‡æ— æ•ˆæ–‡ä»¶ {file_path}: {error}")
        
        if len(valid_files) < 2:
            print(f"âš ï¸  æœ‰æ•ˆè§†é¢‘æ–‡ä»¶ä¸è¶³2ä¸ª ({len(valid_files)}ä¸ª)")
            return []
        
        print(f"ğŸ“ å¤„ç† {len(valid_files)} ä¸ªæœ‰æ•ˆè§†é¢‘æ–‡ä»¶")
        
        # ç”Ÿæˆé…å¯¹å¹¶æ‰§è¡Œæ¯”è¾ƒ
        video_pairs = list(combinations(valid_files, 2))
        
        # åˆå§‹åŒ–åˆ†æå™¨
        self.initialize_analyzer()
        
        results = []
        progress = ProgressTracker(len(video_pairs), "æ‰¹é‡æ¯”è¾ƒè¿›åº¦")
        
        for pair in video_pairs:
            result = self.compare_file_pair(pair)
            results.append(result)
            
            progress.update(1, f"å®Œæˆ: {os.path.basename(pair[0])} vs {os.path.basename(pair[1])}")
        
        progress.finish("æ‰¹é‡æ¯”è¾ƒå®Œæˆ")
        
        # ä¿å­˜ç»“æœ
        if output_file:
            self.save_results(results, output_file)
        
        return results
    
    def save_results(self, results: list, output_file: str):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        ensure_directory(os.path.dirname(output_file))
        
        file_ext = Path(output_file).suffix.lower()
        
        try:
            if file_ext == '.json':
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
            
            elif file_ext == '.csv':
                self.save_results_csv(results, output_file)
            
            else:
                # é»˜è®¤ä¿å­˜ä¸ºJSON
                output_file = output_file + '.json'
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    def save_results_csv(self, results: list, output_file: str):
        """ä¿å­˜ç»“æœä¸ºCSVæ ¼å¼"""
        if not results:
            return
        
        # å®šä¹‰CSVåˆ—
        csv_columns = [
            'video1_file', 'video2_file', 'comparison_id',
            'overall_similarity_percent', 'is_similar',
            'phash_similarity_percent', 'cnn_similarity_percent', 'audio_similarity_percent',
            'pHash_distance', 'cnn_cosine_distance', 'audio_difference_ratio',
            'processing_time_seconds', 'analysis_time'
        ]
        
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=csv_columns)
            writer.writeheader()
            
            for result in results:
                # åªå†™å…¥æœ‰æ•ˆç»“æœ
                if 'error' not in result:
                    row_data = {col: result.get(col, '') for col in csv_columns}
                    writer.writerow(row_data)
    
    def generate_summary_report(self, results: list, source_directory: str = ""):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        if not results:
            return
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_comparisons = len(results)
        successful_comparisons = len([r for r in results if 'error' not in r])
        failed_comparisons = total_comparisons - successful_comparisons
        
        # ç›¸ä¼¼åº¦ç»Ÿè®¡
        successful_results = [r for r in results if 'error' not in r]
        if successful_results:
            similar_pairs = len([r for r in successful_results if r.get('is_similar', False)])
            
            # ç›¸ä¼¼åº¦åˆ†å¸ƒ
            similarities = [r.get('overall_similarity_percent', 0) for r in successful_results]
            avg_similarity = sum(similarities) / len(similarities) if similarities else 0
            max_similarity = max(similarities) if similarities else 0
            min_similarity = min(similarities) if similarities else 0
            
            # æ‰¾å‡ºæœ€ç›¸ä¼¼çš„å‡ å¯¹
            top_similar = sorted(successful_results, 
                               key=lambda x: x.get('overall_similarity_percent', 0), 
                               reverse=True)[:5]
        else:
            similar_pairs = 0
            avg_similarity = max_similarity = min_similarity = 0
            top_similar = []
        
        # ç”ŸæˆæŠ¥å‘Š
        print("\n" + "="*60)
        print("ğŸ“Š æ‰¹é‡æ¯”è¾ƒæ±‡æ€»æŠ¥å‘Š")
        print("="*60)
        
        if source_directory:
            print(f"ğŸ“ æºç›®å½•: {source_directory}")
        
        print(f"ğŸ“ˆ æ¯”è¾ƒç»Ÿè®¡:")
        print(f"  â€¢ æ€»æ¯”è¾ƒæ¬¡æ•°: {total_comparisons}")
        print(f"  â€¢ æˆåŠŸæ¯”è¾ƒ: {successful_comparisons}")
        print(f"  â€¢ å¤±è´¥æ¯”è¾ƒ: {failed_comparisons}")
        print(f"  â€¢ ç›¸ä¼¼å¯¹æ•°: {similar_pairs}")
        print(f"  â€¢ ç›¸ä¼¼æ¯”ä¾‹: {(similar_pairs/successful_comparisons*100):.1f}%" if successful_comparisons > 0 else "  â€¢ ç›¸ä¼¼æ¯”ä¾‹: 0%")
        
        if successful_results:
            print(f"\nğŸ“Š ç›¸ä¼¼åº¦åˆ†å¸ƒ:")
            print(f"  â€¢ å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.1f}%")
            print(f"  â€¢ æœ€é«˜ç›¸ä¼¼åº¦: {max_similarity:.1f}%")
            print(f"  â€¢ æœ€ä½ç›¸ä¼¼åº¦: {min_similarity:.1f}%")
            
            if top_similar:
                print(f"\nğŸ† æœ€ç›¸ä¼¼çš„è§†é¢‘å¯¹:")
                for i, result in enumerate(top_similar[:3], 1):
                    print(f"  {i}. {result['video1_file']} vs {result['video2_file']}")
                    print(f"     ç›¸ä¼¼åº¦: {result['overall_similarity_percent']:.1f}%")
        
        # ä¿å­˜æ±‡æ€»æŠ¥å‘Š
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        summary_file = os.path.join(self.config.files.output_dir, 
                                  f"batch_summary_{timestamp}.txt")
        
        try:
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write("æ‰¹é‡è§†é¢‘ç›¸ä¼¼åº¦æ¯”è¾ƒæ±‡æ€»æŠ¥å‘Š\n")
                f.write("="*50 + "\n\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                if source_directory:
                    f.write(f"æºç›®å½•: {source_directory}\n")
                f.write(f"\næ¯”è¾ƒç»Ÿè®¡:\n")
                f.write(f"æ€»æ¯”è¾ƒæ¬¡æ•°: {total_comparisons}\n")
                f.write(f"æˆåŠŸæ¯”è¾ƒ: {successful_comparisons}\n")
                f.write(f"å¤±è´¥æ¯”è¾ƒ: {failed_comparisons}\n")
                f.write(f"ç›¸ä¼¼å¯¹æ•°: {similar_pairs}\n")
                
                if successful_results:
                    f.write(f"\nç›¸ä¼¼åº¦åˆ†å¸ƒ:\n")
                    f.write(f"å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.1f}%\n")
                    f.write(f"æœ€é«˜ç›¸ä¼¼åº¦: {max_similarity:.1f}%\n")
                    f.write(f"æœ€ä½ç›¸ä¼¼åº¦: {min_similarity:.1f}%\n")
                    
                    if top_similar:
                        f.write(f"\næœ€ç›¸ä¼¼çš„è§†é¢‘å¯¹:\n")
                        for i, result in enumerate(top_similar, 1):
                            f.write(f"{i}. {result['video1_file']} vs {result['video2_file']}\n")
                            f.write(f"   ç›¸ä¼¼åº¦: {result['overall_similarity_percent']:.1f}%\n")
            
            print(f"\nğŸ“„ æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {summary_file}")
            
        except Exception as e:
            print(f"âš ï¸  æ±‡æ€»æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")
    
    def find_duplicate_groups(self, results: list, similarity_threshold: float = None) -> list:
        """
        ä»æ¯”è¾ƒç»“æœä¸­æ‰¾å‡ºé‡å¤è§†é¢‘ç»„
        
        Args:
            results: æ¯”è¾ƒç»“æœåˆ—è¡¨
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
        
        Returns:
            é‡å¤ç»„åˆ—è¡¨
        """
        if similarity_threshold is None:
            similarity_threshold = self.config.thresholds.overall_threshold * 100
        
        # æ„å»ºå›¾ç»“æ„
        video_graph = {}
        similar_pairs = []
        
        for result in results:
            if 'error' in result:
                continue
            
            video1 = result['video1_full_path']
            video2 = result['video2_full_path']
            similarity = result.get('overall_similarity_percent', 0)
            
            # è®°å½•ç›¸ä¼¼çš„é…å¯¹
            if similarity >= similarity_threshold:
                similar_pairs.append((video1, video2, similarity))
                
                # å»ºç«‹å›¾è¿æ¥
                if video1 not in video_graph:
                    video_graph[video1] = set()
                if video2 not in video_graph:
                    video_graph[video2] = set()
                
                video_graph[video1].add(video2)
                video_graph[video2].add(video1)
        
        # æ‰¾å‡ºè¿é€šåˆ†é‡ï¼ˆé‡å¤ç»„ï¼‰
        visited = set()
        duplicate_groups = []
        
        def dfs(video, group):
            if video in visited:
                return
            visited.add(video)
            group.append(video)
            
            for neighbor in video_graph.get(video, []):
                dfs(neighbor, group)
        
        for video in video_graph:
            if video not in visited:
                group = []
                dfs(video, group)
                if len(group) > 1:
                    duplicate_groups.append(sorted(group))
        
        return duplicate_groups
    
    def print_duplicate_groups(self, results: list):
        """æ‰“å°é‡å¤è§†é¢‘ç»„"""
        duplicate_groups = self.find_duplicate_groups(results)
        
        if not duplicate_groups:
            print("âœ… æœªå‘ç°é‡å¤è§†é¢‘")
            return
        
        print(f"\nğŸ” å‘ç° {len(duplicate_groups)} ä¸ªé‡å¤è§†é¢‘ç»„:")
        print("-" * 50)
        
        for i, group in enumerate(duplicate_groups, 1):
            print(f"\né‡å¤ç»„ {i} ({len(group)} ä¸ªæ–‡ä»¶):")
            for video in group:
                filename = os.path.basename(video)
                print(f"  â€¢ {filename}")
        
        # ä¿å­˜é‡å¤ç»„ä¿¡æ¯
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        duplicates_file = os.path.join(self.config.files.output_dir, 
                                     f"duplicate_groups_{timestamp}.json")
        
        try:
            duplicate_data = {
                'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'threshold_used': self.config.thresholds.overall_threshold * 100,
                'total_groups': len(duplicate_groups),
                'groups': [
                    {
                        'group_id': i,
                        'file_count': len(group),
                        'files': [
                            {
                                'filename': os.path.basename(video),
                                'full_path': video
                            } for video in group
                        ]
                    } for i, group in enumerate(duplicate_groups, 1)
                ]
            }
            
            with open(duplicates_file, 'w', encoding='utf-8') as f:
                json.dump(duplicate_data, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ“„ é‡å¤ç»„ä¿¡æ¯å·²ä¿å­˜: {duplicates_file}")
            
        except Exception as e:
            print(f"âš ï¸  é‡å¤ç»„ä¿¡æ¯ä¿å­˜å¤±è´¥: {e}")

def main():
    """å‘½ä»¤è¡Œä¸»ç¨‹åº"""
    parser = argparse.ArgumentParser(description='æ‰¹é‡è§†é¢‘ç›¸ä¼¼åº¦åˆ†æå·¥å…·')
    
    subparsers = parser.add_subparsers(dest='command', help='æ“ä½œå‘½ä»¤')
    
    # ç›®å½•æ¯”è¾ƒå‘½ä»¤
    dir_parser = subparsers.add_parser('directory', help='æ¯”è¾ƒç›®å½•ä¸­çš„æ‰€æœ‰è§†é¢‘')
    dir_parser.add_argument('directory', help='è§†é¢‘ç›®å½•è·¯å¾„')
    dir_parser.add_argument('--recursive', '-r', action='store_true', help='é€’å½’æœç´¢å­ç›®å½•')
    dir_parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    dir_parser.add_argument('--workers', '-w', type=int, help='å¹¶è¡Œå·¥ä½œæ•°')
    dir_parser.add_argument('--find-duplicates', '-d', action='store_true', help='æŸ¥æ‰¾é‡å¤è§†é¢‘ç»„')
    
    # æ–‡ä»¶åˆ—è¡¨æ¯”è¾ƒå‘½ä»¤
    files_parser = subparsers.add_parser('files', help='æ¯”è¾ƒæŒ‡å®šçš„è§†é¢‘æ–‡ä»¶åˆ—è¡¨')
    files_parser.add_argument('files', nargs='+', help='è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨')
    files_parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    clean_temp_files(config.files.temp_dir)
    
    processor = BatchProcessor()
    
    try:
        if args.command == 'directory':
            print(f"ğŸ¬ æ‰¹é‡æ¯”è¾ƒç›®å½•: {args.directory}")
            
            results = processor.batch_compare_directory(
                args.directory,
                recursive=args.recursive,
                max_workers=args.workers,
                output_file=args.output
            )
            
            if args.find_duplicates and results:
                processor.print_duplicate_groups(results)
        
        elif args.command == 'files':
            print(f"ğŸ¬ æ‰¹é‡æ¯”è¾ƒ {len(args.files)} ä¸ªæ–‡ä»¶")
            
            results = processor.batch_compare_file_list(
                args.files,
                output_file=args.output
            )
        
        print("\nâœ… æ‰¹é‡å¤„ç†å®Œæˆ")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
        traceback.print_exc()

if __name__ == '__main__':
    main()