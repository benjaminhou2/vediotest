#!/usr/bin/env python3
# TikTok & æŠ–éŸ³éšå½¢æ°´å°æ£€æµ‹å™¨
# åˆ†æçŸ­è§†é¢‘ä¸­çš„å„ç§éšå½¢æ°´å°ä¿¡æ¯

import cv2
import numpy as np
import os
import json
import sys
from datetime import datetime
import hashlib
import struct
from PIL import Image, ImageEnhance
import wave
import librosa
import matplotlib.pyplot as plt
from scipy.fft import fft2, ifft2
from scipy.spatial.distance import cosine
from moviepy.editor import VideoFileClip
import exifread
from pathlib import Path

class WatermarkDetector:
    """TikTok & æŠ–éŸ³éšå½¢æ°´å°æ£€æµ‹å™¨"""
    
    def __init__(self):
        self.detection_methods = [
            'metadata_analysis',      # å…ƒæ•°æ®åˆ†æ
            'dct_watermark',         # DCTé¢‘åŸŸæ°´å°
            'lsb_steganography',     # LSBéšå†™æœ¯
            'dwt_watermark',         # å°æ³¢å˜æ¢æ°´å°
            'spread_spectrum',       # æ‰©é¢‘æ°´å°
            'frame_correlation',     # å¸§é—´ç›¸å…³æ€§
            'audio_watermark',       # éŸ³é¢‘æ°´å°
            'temporal_pattern',      # æ—¶åŸŸæ¨¡å¼
            'pixel_analysis',        # åƒç´ çº§åˆ†æ
            'color_channel_analysis', # é¢œè‰²é€šé“åˆ†æ
            'edge_detection_anomaly', # è¾¹ç¼˜æ£€æµ‹å¼‚å¸¸
            'fourier_analysis'       # å‚…é‡Œå¶åˆ†æ
        ]
        
        self.watermark_info = {}
        
    def analyze_video(self, video_path: str) -> dict:
        """
        å…¨é¢åˆ†æè§†é¢‘ä¸­çš„éšå½¢æ°´å°
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        print(f"ğŸ” å¼€å§‹åˆ†æè§†é¢‘: {os.path.basename(video_path)}")
        
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        
        results = {
            'file_info': self._get_file_info(video_path),
            'analysis_time': datetime.now().isoformat(),
            'watermarks_detected': {},
            'confidence_scores': {},
            'summary': {}
        }
        
        # 1. å…ƒæ•°æ®åˆ†æ
        print("ğŸ“‹ åˆ†æè§†é¢‘å…ƒæ•°æ®...")
        results['watermarks_detected']['metadata'] = self._analyze_metadata(video_path)
        
        # 2. è§†é¢‘å¸§åˆ†æ
        print("ğŸ¬ åˆ†æè§†é¢‘å¸§...")
        frame_results = self._analyze_video_frames(video_path)
        results['watermarks_detected'].update(frame_results)
        
        # 3. éŸ³é¢‘åˆ†æ
        print("ğŸµ åˆ†æéŸ³é¢‘è½¨é“...")
        audio_results = self._analyze_audio(video_path)
        results['watermarks_detected']['audio'] = audio_results
        
        # 4. æ–‡ä»¶ç»“æ„åˆ†æ
        print("ğŸ”§ åˆ†ææ–‡ä»¶ç»“æ„...")
        structure_results = self._analyze_file_structure(video_path)
        results['watermarks_detected']['file_structure'] = structure_results
        
        # 5. æ—¶åŸŸåˆ†æ
        print("â±ï¸ åˆ†ææ—¶åŸŸç‰¹å¾...")
        temporal_results = self._analyze_temporal_patterns(video_path)
        results['watermarks_detected']['temporal'] = temporal_results
        
        # 6. ç”Ÿæˆç½®ä¿¡åº¦åˆ†æ•°
        results['confidence_scores'] = self._calculate_confidence_scores(results['watermarks_detected'])
        
        # 7. ç”Ÿæˆåˆ†ææ‘˜è¦
        results['summary'] = self._generate_summary(results)
        
        print("âœ… æ°´å°åˆ†æå®Œæˆ")
        return results
    
    def _get_file_info(self, video_path: str) -> dict:
        """è·å–æ–‡ä»¶åŸºæœ¬ä¿¡æ¯"""
        stat = os.stat(video_path)
        file_hash = self._calculate_file_hash(video_path)
        
        try:
            cap = cv2.VideoCapture(video_path)
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            duration = frame_count / fps if fps > 0 else 0
            cap.release()
        except:
            fps = frame_count = width = height = duration = 0
        
        return {
            'filename': os.path.basename(video_path),
            'size_bytes': stat.st_size,
            'size_mb': stat.st_size / (1024 * 1024),
            'created_time': datetime.fromtimestamp(stat.st_ctime).isoformat(),
            'modified_time': datetime.fromtimestamp(stat.st_mtime).isoformat(),
            'md5_hash': file_hash,
            'video_info': {
                'fps': fps,
                'frame_count': frame_count,
                'resolution': f"{width}x{height}",
                'duration_seconds': duration
            }
        }
    
    def _calculate_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶MD5å“ˆå¸Œ"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def _analyze_metadata(self, video_path: str) -> dict:
        """åˆ†æè§†é¢‘å…ƒæ•°æ®ä¸­çš„æ°´å°ä¿¡æ¯"""
        metadata = {}
        
        try:
            # ä½¿ç”¨moviepyæå–å…ƒæ•°æ®
            clip = VideoFileClip(video_path)
            if hasattr(clip, 'reader') and hasattr(clip.reader, 'infos'):
                metadata['moviepy_info'] = clip.reader.infos
            clip.close()
        except Exception as e:
            metadata['moviepy_error'] = str(e)
        
        try:
            # ä½¿ç”¨OpenCVæå–å…ƒæ•°æ®
            cap = cv2.VideoCapture(video_path)
            
            # æ£€æŸ¥ç¼–ç å™¨ä¿¡æ¯
            fourcc = int(cap.get(cv2.CAP_PROP_FOURCC))
            codec = struct.pack('<I', fourcc).decode('utf-8', errors='ignore')
            
            metadata['opencv_info'] = {
                'codec': codec,
                'backend': cap.getBackendName() if hasattr(cap, 'getBackendName') else 'unknown'
            }
            cap.release()
        except Exception as e:
            metadata['opencv_error'] = str(e)
        
        # æ£€æŸ¥æ–‡ä»¶å¤´éƒ¨ç‰¹å¾
        metadata['file_header'] = self._analyze_file_header(video_path)
        
        # æ£€æŸ¥æ½œåœ¨çš„å¹³å°æ ‡è¯†
        metadata['platform_signatures'] = self._detect_platform_signatures(video_path)
        
        return metadata
    
    def _analyze_file_header(self, video_path: str) -> dict:
        """åˆ†ææ–‡ä»¶å¤´éƒ¨ä¿¡æ¯"""
        header_info = {}
        
        try:
            with open(video_path, 'rb') as f:
                # è¯»å–å‰1KBä½œä¸ºæ–‡ä»¶å¤´
                header = f.read(1024)
                
                # æ£€æŸ¥æ–‡ä»¶é­”æ•°
                if header[:4] == b'\x00\x00\x00\x20':
                    header_info['format'] = 'MP4'
                elif header[:3] == b'FLV':
                    header_info['format'] = 'FLV'
                elif header[:4] == b'RIFF':
                    header_info['format'] = 'AVI'
                
                # æŸ¥æ‰¾å¯ç–‘çš„å­—ç¬¦ä¸²æ¨¡å¼
                suspicious_patterns = [
                    b'tiktok', b'douyin', b'bytedance',
                    b'TikTok', b'Douyin', b'ByteDance',
                    b'watermark', b'signature', b'uid'
                ]
                
                found_patterns = []
                for pattern in suspicious_patterns:
                    if pattern in header:
                        found_patterns.append(pattern.decode('utf-8', errors='ignore'))
                
                header_info['suspicious_patterns'] = found_patterns
                header_info['header_hex'] = header[:100].hex()  # å‰100å­—èŠ‚çš„åå…­è¿›åˆ¶
                
        except Exception as e:
            header_info['error'] = str(e)
        
        return header_info
    
    def _detect_platform_signatures(self, video_path: str) -> dict:
        """æ£€æµ‹å¹³å°ç‰¹æœ‰çš„ç­¾å"""
        signatures = {
            'tiktok_indicators': [],
            'douyin_indicators': [],
            'generic_watermarks': []
        }
        
        try:
            # è¯»å–æ–‡ä»¶çš„å¤šä¸ªéƒ¨åˆ†
            file_size = os.path.getsize(video_path)
            sample_positions = [0, file_size//4, file_size//2, file_size*3//4, max(0, file_size-1024)]
            
            with open(video_path, 'rb') as f:
                for pos in sample_positions:
                    f.seek(pos)
                    chunk = f.read(1024)
                    
                    # TikTokç‰¹å¾
                    tiktok_patterns = [
                        b'tiktok', b'tt_', b'musical.ly',
                        b'douyin', b'bytedance'
                    ]
                    
                    for pattern in tiktok_patterns:
                        if pattern in chunk.lower():
                            signatures['tiktok_indicators'].append({
                                'pattern': pattern.decode('utf-8', errors='ignore'),
                                'position': pos,
                                'context': chunk[max(0, chunk.find(pattern)-10):chunk.find(pattern)+30].hex()
                            })
                    
                    # æŠ–éŸ³ç‰¹å¾  
                    douyin_patterns = [
                        b'\xe6\x8a\x96\xe9\x9f\xb3',  # "æŠ–éŸ³" UTF-8ç¼–ç 
                        b'douyin', b'aweme'
                    ]
                    
                    for pattern in douyin_patterns:
                        if pattern in chunk.lower():
                            signatures['douyin_indicators'].append({
                                'pattern': pattern.hex() if len(pattern) > 10 else pattern.decode('utf-8', errors='ignore'),
                                'position': pos,
                                'context': chunk[max(0, chunk.find(pattern)-10):chunk.find(pattern)+30].hex()
                            })
                            
        except Exception as e:
            signatures['error'] = str(e)
        
        return signatures
    
    def _analyze_video_frames(self, video_path: str) -> dict:
        """åˆ†æè§†é¢‘å¸§ä¸­çš„éšå½¢æ°´å°"""
        frame_results = {
            'dct_watermark': {},
            'lsb_analysis': {},
            'dwt_analysis': {},
            'pixel_anomalies': {},
            'color_channel_analysis': {},
            'edge_anomalies': {},
            'fourier_analysis': {}
        }
        
        cap = cv2.VideoCapture(video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # é‡‡æ ·å¸§è¿›è¡Œåˆ†æï¼ˆé¿å…å¤„ç†æ‰€æœ‰å¸§ï¼‰
        sample_frames = min(20, total_frames)
        frame_indices = np.linspace(0, total_frames-1, sample_frames, dtype=int)
        
        frames_data = []
        
        for i, frame_idx in enumerate(frame_indices):
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            
            if not ret:
                continue
                
            frames_data.append(frame)
            
            # æ¯éš”å‡ å¸§è¿›è¡Œè¯¦ç»†åˆ†æ
            if i % 5 == 0:
                print(f"  åˆ†æç¬¬ {frame_idx} å¸§...")
                
                # DCTé¢‘åŸŸåˆ†æ
                dct_result = self._analyze_dct_watermark(frame)
                if dct_result['confidence'] > 0.3:
                    frame_results['dct_watermark'][f'frame_{frame_idx}'] = dct_result
                
                # LSBéšå†™æœ¯æ£€æµ‹
                lsb_result = self._analyze_lsb_steganography(frame)
                if lsb_result['suspicious_pixels'] > 100:
                    frame_results['lsb_analysis'][f'frame_{frame_idx}'] = lsb_result
                
                # å°æ³¢å˜æ¢åˆ†æ
                dwt_result = self._analyze_dwt_watermark(frame)
                if dwt_result['watermark_strength'] > 0.2:
                    frame_results['dwt_analysis'][f'frame_{frame_idx}'] = dwt_result
                
                # åƒç´ å¼‚å¸¸æ£€æµ‹
                pixel_result = self._analyze_pixel_anomalies(frame)
                frame_results['pixel_anomalies'][f'frame_{frame_idx}'] = pixel_result
        
        cap.release()
        
        # å¸§é—´ç›¸å…³æ€§åˆ†æ
        if len(frames_data) > 1:
            frame_results['frame_correlation'] = self._analyze_frame_correlation(frames_data)
        
        # é¢œè‰²é€šé“åˆ†æ
        if frames_data:
            frame_results['color_channel_analysis'] = self._analyze_color_channels(frames_data[0])
        
        return frame_results
    
    def _analyze_dct_watermark(self, frame: np.ndarray) -> dict:
        """DCTé¢‘åŸŸæ°´å°æ£€æµ‹"""
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # åˆ†å—DCTå˜æ¢
            block_size = 8
            h, w = gray.shape
            
            watermark_blocks = []
            suspicious_blocks = 0
            
            for i in range(0, h-block_size, block_size):
                for j in range(0, w-block_size, block_size):
                    block = gray[i:i+block_size, j:j+block_size].astype(np.float32)
                    
                    # DCTå˜æ¢
                    dct_block = cv2.dct(block)
                    
                    # æ£€æŸ¥ä¸­é¢‘ç³»æ•°å¼‚å¸¸
                    mid_freq_coeffs = dct_block[2:6, 2:6]
                    
                    # è®¡ç®—å¼‚å¸¸ç¨‹åº¦
                    anomaly_score = np.std(mid_freq_coeffs) / (np.mean(np.abs(mid_freq_coeffs)) + 1e-8)
                    
                    if anomaly_score > 2.0:  # é˜ˆå€¼å¯è°ƒ
                        suspicious_blocks += 1
                        watermark_blocks.append({
                            'position': (i, j),
                            'anomaly_score': float(anomaly_score),
                            'coefficients': mid_freq_coeffs.flatten().tolist()
                        })
            
            total_blocks = ((h//block_size) * (w//block_size))
            confidence = suspicious_blocks / max(total_blocks, 1)
            
            return {
                'suspicious_blocks': suspicious_blocks,
                'total_blocks': total_blocks,
                'confidence': confidence,
                'watermark_blocks': watermark_blocks[:10]  # åªä¿å­˜å‰10ä¸ª
            }
            
        except Exception as e:
            return {'error': str(e), 'confidence': 0}
    
    def _analyze_lsb_steganography(self, frame: np.ndarray) -> dict:
        """LSBéšå†™æœ¯æ£€æµ‹"""
        try:
            h, w, c = frame.shape
            suspicious_pixels = 0
            lsb_patterns = []
            
            # æ£€æŸ¥æ¯ä¸ªé¢œè‰²é€šé“çš„LSB
            for channel in range(c):
                channel_data = frame[:, :, channel]
                
                # æå–LSB
                lsb_plane = channel_data & 1
                
                # è®¡ç®—LSBçš„éšæœºæ€§
                lsb_flat = lsb_plane.flatten()
                
                # è®¡ç®—è¿ç»­ä½çš„åˆ†å¸ƒ
                consecutive_ones = 0
                consecutive_zeros = 0
                max_consecutive = 0
                current_consecutive = 1
                
                for i in range(1, len(lsb_flat)):
                    if lsb_flat[i] == lsb_flat[i-1]:
                        current_consecutive += 1
                    else:
                        max_consecutive = max(max_consecutive, current_consecutive)
                        current_consecutive = 1
                
                # å¦‚æœLSBæ¨¡å¼è¿‡äºè§„å¾‹ï¼Œå¯èƒ½å­˜åœ¨éšå†™
                randomness = np.std(lsb_flat)
                if randomness < 0.45 or max_consecutive > 50:
                    suspicious_pixels += np.sum(lsb_plane)
                    lsb_patterns.append({
                        'channel': channel,
                        'randomness': float(randomness),
                        'max_consecutive': max_consecutive,
                        'lsb_mean': float(np.mean(lsb_flat))
                    })
            
            return {
                'suspicious_pixels': suspicious_pixels,
                'total_pixels': h * w,
                'lsb_patterns': lsb_patterns,
                'suspicion_ratio': suspicious_pixels / (h * w)
            }
            
        except Exception as e:
            return {'error': str(e), 'suspicious_pixels': 0}
    
    def _analyze_dwt_watermark(self, frame: np.ndarray) -> dict:
        """å°æ³¢å˜æ¢æ°´å°æ£€æµ‹"""
        try:
            import pywt
            
            # è½¬æ¢ä¸ºç°åº¦
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).astype(np.float32)
            
            # å¤šçº§å°æ³¢åˆ†è§£
            coeffs = pywt.wavedec2(gray, 'haar', level=3)
            
            watermark_strength = 0
            suspicious_subbands = []
            
            # æ£€æŸ¥å„ä¸ªå­å¸¦çš„å¼‚å¸¸
            for level, (cH, cV, cD) in enumerate(coeffs[1:], 1):
                # è®¡ç®—é«˜é¢‘å­å¸¦çš„èƒ½é‡åˆ†å¸ƒ
                energy_h = np.mean(cH ** 2)
                energy_v = np.mean(cV ** 2)
                energy_d = np.mean(cD ** 2)
                
                # æ£€æŸ¥èƒ½é‡åˆ†å¸ƒå¼‚å¸¸
                energy_ratio = energy_d / (energy_h + energy_v + 1e-8)
                
                if energy_ratio > 1.5 or energy_ratio < 0.3:
                    watermark_strength += energy_ratio * 0.1
                    suspicious_subbands.append({
                        'level': level,
                        'energy_ratio': float(energy_ratio),
                        'energy_h': float(energy_h),
                        'energy_v': float(energy_v),
                        'energy_d': float(energy_d)
                    })
            
            return {
                'watermark_strength': min(watermark_strength, 1.0),
                'suspicious_subbands': suspicious_subbands,
                'dwt_levels': len(coeffs) - 1
            }
            
        except ImportError:
            return {'error': 'PyWavelets not installed', 'watermark_strength': 0}
        except Exception as e:
            return {'error': str(e), 'watermark_strength': 0}
    
    def _analyze_pixel_anomalies(self, frame: np.ndarray) -> dict:
        """åƒç´ çº§å¼‚å¸¸æ£€æµ‹"""
        try:
            h, w, c = frame.shape
            
            # è®¡ç®—ç›¸é‚»åƒç´ å·®å¼‚
            diff_h = np.abs(frame[1:, :, :] - frame[:-1, :, :])
            diff_v = np.abs(frame[:, 1:, :] - frame[:, :-1, :])
            
            # ç»Ÿè®¡å¼‚å¸¸åƒç´ 
            anomaly_threshold = 30
            anomalous_h = np.sum(diff_h > anomaly_threshold)
            anomalous_v = np.sum(diff_v > anomaly_threshold)
            
            # æ£€æŸ¥åƒç´ å€¼åˆ†å¸ƒ
            pixel_hist = np.histogram(frame.flatten(), bins=256)[0]
            distribution_entropy = -np.sum((pixel_hist / np.sum(pixel_hist)) * 
                                         np.log2(pixel_hist / np.sum(pixel_hist) + 1e-8))
            
            return {
                'anomalous_horizontal': int(anomalous_h),
                'anomalous_vertical': int(anomalous_v),
                'total_pixels': h * w,
                'distribution_entropy': float(distribution_entropy),
                'anomaly_ratio': (anomalous_h + anomalous_v) / (2 * h * w)
            }
            
        except Exception as e:
            return {'error': str(e)}
    
    def _analyze_frame_correlation(self, frames: list) -> dict:
        """å¸§é—´ç›¸å…³æ€§åˆ†æ"""
        try:
            correlations = []
            
            for i in range(len(frames) - 1):
                frame1 = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)
                frame2 = cv2.cvtColor(frames[i+1], cv2.COLOR_BGR2GRAY)
                
                # è®¡ç®—ç»“æ„ç›¸ä¼¼æ€§
                correlation = cv2.matchTemplate(frame1, frame2, cv2.TM_CCOEFF_NORMED)[0][0]
                correlations.append(correlation)
            
            # æ£€æŸ¥å¼‚å¸¸çš„ç›¸å…³æ€§æ¨¡å¼
            corr_mean = np.mean(correlations)
            corr_std = np.std(correlations)
            
            # å¯»æ‰¾å‘¨æœŸæ€§æ¨¡å¼
            fft_corr = np.fft.fft(correlations)
            dominant_freq = np.argmax(np.abs(fft_corr[1:len(fft_corr)//2])) + 1
            
            return {
                'correlation_mean': float(corr_mean),
                'correlation_std': float(corr_std),
                'correlations': [float(c) for c in correlations],
                'dominant_frequency': int(dominant_freq),
                'periodic_watermark_suspected': corr_std < 0.05 and corr_mean > 0.8
            }
            
        except Exception as e:
            return {'error': str(e)}
    
    def _analyze_color_channels(self, frame: np.ndarray) -> dict:
        """é¢œè‰²é€šé“åˆ†æ"""
        try:
            b, g, r = cv2.split(frame)
            
            channel_analysis = {}
            
            for name, channel in [('blue', b), ('green', g), ('red', r)]:
                # è®¡ç®—é€šé“ç»Ÿè®¡
                mean_val = np.mean(channel)
                std_val = np.std(channel)
                
                # æ£€æŸ¥é€šé“é—´çš„å¼‚å¸¸å…³ç³»
                hist = np.histogram(channel, bins=256)[0]
                entropy = -np.sum((hist / np.sum(hist)) * np.log2(hist / np.sum(hist) + 1e-8))
                
                channel_analysis[name] = {
                    'mean': float(mean_val),
                    'std': float(std_val),
                    'entropy': float(entropy),
                    'peak_values': np.where(hist > np.max(hist) * 0.8)[0].tolist()
                }
            
            # æ£€æŸ¥é€šé“é—´ç›¸å…³æ€§
            correlations = {
                'bg_correlation': float(np.corrcoef(b.flatten(), g.flatten())[0, 1]),
                'br_correlation': float(np.corrcoef(b.flatten(), r.flatten())[0, 1]),
                'gr_correlation': float(np.corrcoef(g.flatten(), r.flatten())[0, 1])
            }
            
            return {
                'channels': channel_analysis,
                'correlations': correlations,
                'suspicious_channel_imbalance': any(abs(c) < 0.7 for c in correlations.values())
            }
            
        except Exception as e:
            return {'error': str(e)}
    
    def _analyze_audio(self, video_path: str) -> dict:
        """éŸ³é¢‘æ°´å°æ£€æµ‹"""
        try:
            # æå–éŸ³é¢‘
            clip = VideoFileClip(video_path)
            if clip.audio is None:
                return {'error': 'No audio track found'}
            
            audio_path = 'temp_audio_analysis.wav'
            clip.audio.write_audiofile(audio_path, logger=None, verbose=False)
            clip.close()
            
            # ä½¿ç”¨librosaåˆ†æéŸ³é¢‘
            y, sr = librosa.load(audio_path, sr=None)
            
            # é¢‘è°±åˆ†æ
            stft = librosa.stft(y)
            magnitude = np.abs(stft)
            
            # æ£€æµ‹éšè—é¢‘ç‡
            freq_bins = librosa.fft_frequencies(sr=sr)
            
            # å¯»æ‰¾å¼‚å¸¸çš„é¢‘ç‡å³°å€¼
            freq_energy = np.mean(magnitude, axis=1)
            peaks = np.where(freq_energy > np.mean(freq_energy) + 2 * np.std(freq_energy))[0]
            
            # æ£€æµ‹é™éŸ³æ®µä¸­çš„éšè—ä¿¡å·
            silence_threshold = 0.01
            silent_frames = np.where(np.abs(y) < silence_threshold)[0]
            
            if len(silent_frames) > 0:
                silent_audio = y[silent_frames]
                silent_energy = np.mean(silent_audio ** 2)
            else:
                silent_energy = 0
            
            # æ£€æµ‹ä¸å¯å¬è§çš„é«˜é¢‘ä¿¡å·
            high_freq_start = int(len(freq_bins) * 0.8)  # é«˜é¢‘éƒ¨åˆ†
            high_freq_energy = np.mean(freq_energy[high_freq_start:])
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(audio_path):
                os.remove(audio_path)
            
            return {
                'sample_rate': sr,
                'duration': len(y) / sr,
                'suspicious_frequencies': [float(freq_bins[p]) for p in peaks],
                'high_freq_energy': float(high_freq_energy),
                'silent_frame_energy': float(silent_energy),
                'spectral_peaks': len(peaks),
                'watermark_suspected': len(peaks) > 5 or high_freq_energy > 0.1
            }
            
        except Exception as e:
            return {'error': str(e)}
    
    def _analyze_file_structure(self, video_path: str) -> dict:
        """æ–‡ä»¶ç»“æ„åˆ†æ"""
        try:
            file_size = os.path.getsize(video_path)
            
            # åˆ†ææ–‡ä»¶çš„ä¸åŒåŒºåŸŸ
            regions = {
                'header': (0, min(8192, file_size//10)),
                'middle': (file_size//2 - 4096, file_size//2 + 4096),
                'footer': (max(0, file_size - 8192), file_size)
            }
            
            structure_analysis = {}
            
            with open(video_path, 'rb') as f:
                for region_name, (start, end) in regions.items():
                    f.seek(start)
                    data = f.read(end - start)
                    
                    # è®¡ç®—ç†µå€¼
                    byte_counts = np.bincount(np.frombuffer(data, dtype=np.uint8), minlength=256)
                    probabilities = byte_counts / len(data)
                    entropy = -np.sum(probabilities * np.log2(probabilities + 1e-8))
                    
                    # æ£€æŸ¥é‡å¤æ¨¡å¼
                    patterns = {}
                    for i in range(len(data) - 4):
                        pattern = data[i:i+4]
                        patterns[pattern] = patterns.get(pattern, 0) + 1
                    
                    most_common = max(patterns.values()) if patterns else 0
                    
                    structure_analysis[region_name] = {
                        'entropy': float(entropy),
                        'size': len(data),
                        'most_common_pattern_count': most_common,
                        'unique_patterns': len(patterns),
                        'suspicious': entropy < 6.0 or most_common > len(data) * 0.1
                    }
            
            return structure_analysis
            
        except Exception as e:
            return {'error': str(e)}
    
    def _analyze_temporal_patterns(self, video_path: str) -> dict:
        """æ—¶åŸŸæ¨¡å¼åˆ†æ"""
        try:
            cap = cv2.VideoCapture(video_path)
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # é‡‡æ ·å¸§çš„å¹³å‡äº®åº¦
            brightness_timeline = []
            frame_indices = np.linspace(0, total_frames-1, min(100, total_frames), dtype=int)
            
            for frame_idx in frame_indices:
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                ret, frame = cap.read()
                
                if ret:
                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                    brightness = np.mean(gray)
                    brightness_timeline.append(brightness)
            
            cap.release()
            
            # åˆ†æäº®åº¦å˜åŒ–æ¨¡å¼
            if len(brightness_timeline) > 10:
                # FFTåˆ†æå¯»æ‰¾å‘¨æœŸæ€§
                fft_brightness = np.fft.fft(brightness_timeline)
                frequencies = np.fft.fftfreq(len(brightness_timeline))
                
                # å¯»æ‰¾æ˜¾è‘—çš„å‘¨æœŸæ€§
                magnitude = np.abs(fft_brightness)
                peak_freq_idx = np.argmax(magnitude[1:len(magnitude)//2]) + 1
                peak_frequency = frequencies[peak_freq_idx]
                
                # è®¡ç®—å˜åŒ–çš„è§„å¾‹æ€§
                brightness_std = np.std(brightness_timeline)
                brightness_mean = np.mean(brightness_timeline)
                
                return {
                    'brightness_timeline': [float(b) for b in brightness_timeline],
                    'brightness_mean': float(brightness_mean),
                    'brightness_std': float(brightness_std),
                    'peak_frequency': float(peak_frequency),
                    'periodic_pattern_detected': magnitude[peak_freq_idx] > np.mean(magnitude) * 3,
                    'regularity_score': float(1.0 / (brightness_std + 1e-8))
                }
            else:
                return {'error': 'Insufficient frames for temporal analysis'}
                
        except Exception as e:
            return {'error': str(e)}
    
    def _calculate_confidence_scores(self, watermarks: dict) -> dict:
        """è®¡ç®—å„ç±»æ°´å°æ£€æµ‹çš„ç½®ä¿¡åº¦åˆ†æ•°"""
        scores = {}
        
        # å…ƒæ•°æ®ç½®ä¿¡åº¦
        metadata = watermarks.get('metadata', {})
        platform_sigs = metadata.get('platform_signatures', {})
        tiktok_count = len(platform_sigs.get('tiktok_indicators', []))
        douyin_count = len(platform_sigs.get('douyin_indicators', []))
        scores['metadata_confidence'] = min((tiktok_count + douyin_count) * 0.2, 1.0)
        
        # è§†é¢‘å¸§ç½®ä¿¡åº¦
        dct_data = watermarks.get('dct_watermark', {})
        if dct_data and not isinstance(dct_data, dict) or 'error' in dct_data:
            scores['dct_confidence'] = 0.0
        else:
            dct_confidence = 0.0
            for frame_data in dct_data.values():
                dct_confidence = max(dct_confidence, frame_data.get('confidence', 0))
            scores['dct_confidence'] = dct_confidence
        
        # LSBç½®ä¿¡åº¦
        lsb_data = watermarks.get('lsb_analysis', {})
        lsb_confidence = 0.0
        for frame_data in lsb_data.values():
            if 'suspicion_ratio' in frame_data:
                lsb_confidence = max(lsb_confidence, frame_data['suspicion_ratio'])
        scores['lsb_confidence'] = min(lsb_confidence * 2, 1.0)
        
        # éŸ³é¢‘ç½®ä¿¡åº¦
        audio_data = watermarks.get('audio', {})
        if 'watermark_suspected' in audio_data:
            scores['audio_confidence'] = 0.8 if audio_data['watermark_suspected'] else 0.2
        else:
            scores['audio_confidence'] = 0.0
        
        # ç»¼åˆç½®ä¿¡åº¦
        all_scores = [score for score in scores.values() if score > 0]
        scores['overall_confidence'] = np.mean(all_scores) if all_scores else 0.0
        
        return scores
    
    def _generate_summary(self, results: dict) -> dict:
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        watermarks = results['watermarks_detected']
        confidence = results['confidence_scores']
        
        # åˆ¤æ–­å¹³å°æ¥æº
        platform = 'unknown'
        metadata = watermarks.get('metadata', {})
        platform_sigs = metadata.get('platform_signatures', {})
        
        if platform_sigs.get('tiktok_indicators'):
            platform = 'tiktok'
        elif platform_sigs.get('douyin_indicators'):
            platform = 'douyin'
        
        # æ£€æµ‹åˆ°çš„æ°´å°ç±»å‹
        detected_watermarks = []
        
        if confidence.get('metadata_confidence', 0) > 0.3:
            detected_watermarks.append('metadata_signatures')
        
        if confidence.get('dct_confidence', 0) > 0.3:
            detected_watermarks.append('dct_frequency_watermark')
        
        if confidence.get('lsb_confidence', 0) > 0.3:
            detected_watermarks.append('lsb_steganography')
        
        if confidence.get('audio_confidence', 0) > 0.5:
            detected_watermarks.append('audio_watermark')
        
        # é£é™©è¯„ä¼°
        overall_conf = confidence.get('overall_confidence', 0)
        if overall_conf > 0.7:
            risk_level = 'high'
        elif overall_conf > 0.4:
            risk_level = 'medium'
        elif overall_conf > 0.1:
            risk_level = 'low'
        else:
            risk_level = 'minimal'
        
        return {
            'suspected_platform': platform,
            'detected_watermark_types': detected_watermarks,
            'risk_level': risk_level,
            'overall_confidence': overall_conf,
            'watermark_count': len(detected_watermarks),
            'analysis_complete': True,
            'recommendations': self._generate_recommendations(detected_watermarks, risk_level)
        }
    
    def _generate_recommendations(self, watermarks: list, risk_level: str) -> list:
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        if 'metadata_signatures' in watermarks:
            recommendations.append("æ£€æµ‹åˆ°å…ƒæ•°æ®ç­¾åï¼Œå»ºè®®æ¸…ç†è§†é¢‘å…ƒæ•°æ®")
        
        if 'dct_frequency_watermark' in watermarks:
            recommendations.append("æ£€æµ‹åˆ°DCTé¢‘åŸŸæ°´å°ï¼Œå¯èƒ½éœ€è¦é‡æ–°ç¼–ç æˆ–å‹ç¼©")
        
        if 'lsb_steganography' in watermarks:
            recommendations.append("æ£€æµ‹åˆ°LSBéšå†™æœ¯ï¼Œå»ºè®®è¿›è¡Œåƒç´ çº§å¤„ç†")
        
        if 'audio_watermark' in watermarks:
            recommendations.append("æ£€æµ‹åˆ°éŸ³é¢‘æ°´å°ï¼Œå»ºè®®å¤„ç†éŸ³é¢‘è½¨é“")
        
        if risk_level == 'high':
            recommendations.append("é«˜é£é™©ï¼šå»ºè®®é¿å…å•†ä¸šä½¿ç”¨æ­¤è§†é¢‘")
        elif risk_level == 'medium':
            recommendations.append("ä¸­ç­‰é£é™©ï¼šå»ºè®®è¿›ä¸€æ­¥å¤„ç†åä½¿ç”¨")
        
        if not watermarks:
            recommendations.append("æœªæ£€æµ‹åˆ°æ˜æ˜¾æ°´å°ï¼Œä½†ä»å»ºè®®è°¨æ…ä½¿ç”¨")
        
        return recommendations
    
    def save_results(self, results: dict, output_path: str = None) -> str:
        """ä¿å­˜åˆ†æç»“æœ"""
        if output_path is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"watermark_analysis_{timestamp}.json"
            output_path = os.path.join('reports', filename)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return ""
    
    def print_summary(self, results: dict):
        """æ‰“å°åˆ†ææ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ” TikTok & æŠ–éŸ³éšå½¢æ°´å°åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        file_info = results['file_info']
        summary = results['summary']
        confidence = results['confidence_scores']
        
        print(f"\nğŸ“ æ–‡ä»¶ä¿¡æ¯:")
        print(f"  â€¢ æ–‡ä»¶å: {file_info['filename']}")
        print(f"  â€¢ å¤§å°: {file_info['size_mb']:.2f} MB")
        print(f"  â€¢ æ—¶é•¿: {file_info['video_info']['duration_seconds']:.1f} ç§’")
        print(f"  â€¢ åˆ†è¾¨ç‡: {file_info['video_info']['resolution']}")
        
        print(f"\nğŸ¯ æ£€æµ‹ç»“æœ:")
        print(f"  â€¢ ç–‘ä¼¼å¹³å°: {summary['suspected_platform'].upper()}")
        print(f"  â€¢ é£é™©çº§åˆ«: {summary['risk_level'].upper()}")
        print(f"  â€¢ æ•´ä½“ç½®ä¿¡åº¦: {summary['overall_confidence']:.2%}")
        print(f"  â€¢ æ£€æµ‹åˆ°æ°´å°ç±»å‹: {len(summary['detected_watermark_types'])} ç§")
        
        if summary['detected_watermark_types']:
            print(f"\nğŸ” æ°´å°ç±»å‹è¯¦æƒ…:")
            for wm_type in summary['detected_watermark_types']:
                print(f"  â€¢ {wm_type}")
        
        print(f"\nğŸ“Š è¯¦ç»†ç½®ä¿¡åº¦:")
        for conf_type, score in confidence.items():
            if score > 0:
                print(f"  â€¢ {conf_type}: {score:.2%}")
        
        if summary['recommendations']:
            print(f"\nğŸ’¡ å»ºè®®:")
            for rec in summary['recommendations']:
                print(f"  â€¢ {rec}")
        
        print("\n" + "="*60)

def main():
    """å‘½ä»¤è¡Œä¸»ç¨‹åº"""
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python watermark_detector.py <è§†é¢‘æ–‡ä»¶è·¯å¾„>")
        print("ç¤ºä¾‹: python watermark_detector.py tiktok_video.mp4")
        sys.exit(1)
    
    video_path = sys.argv[1]
    
    if not os.path.exists(video_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        sys.exit(1)
    
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = WatermarkDetector()
    
    try:
        print("ğŸ¬ TikTok & æŠ–éŸ³éšå½¢æ°´å°æ£€æµ‹å™¨ v1.0")
        print("-" * 50)
        
        # æ‰§è¡Œåˆ†æ
        results = detector.analyze_video(video_path)
        
        # æ˜¾ç¤ºæ‘˜è¦
        detector.print_summary(results)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        output_path = detector.save_results(results)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: {output_path}")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()